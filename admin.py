import streamlit as st
from google import genai
from google.genai import types
import time
import os
import tempfile
from pathlib import Path

# é é¢é…ç½®
st.set_page_config(
    page_title="æª”æ¡ˆæœå°‹å•†åº—ç®¡ç†ç³»çµ±",
    page_icon="ğŸ—„ï¸",
    layout="wide"
)

# åˆå§‹åŒ–å®¢æˆ¶ç«¯
@st.cache_resource
def init_client():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
        st.stop()
    return genai.Client(api_key=api_key)

try:
    client = init_client()
except Exception as e:
    st.error(f"åˆå§‹åŒ–å®¢æˆ¶ç«¯å¤±æ•—: {str(e)}")
    st.info("è«‹ç¢ºèªå·²æ­£ç¢ºè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
    st.stop()

st.title("ğŸ—„ï¸ æª”æ¡ˆæœå°‹å•†åº—ç®¡ç†ç³»çµ±")
st.markdown("ç®¡ç†æ‚¨çš„çŸ¥è­˜åº«å’Œæ³•è¦æ–‡ä»¶")
st.markdown("---")

# æ¨™ç±¤é 
tab1, tab2, tab3 = st.tabs(["ğŸ“ å•†åº—ç®¡ç†", "â¬†ï¸ ä¸Šå‚³æª”æ¡ˆ", "ğŸ“Š çµ±è¨ˆè³‡è¨Š"])

# ===== æ¨™ç±¤é  1: å•†åº—ç®¡ç† =====
with tab1:
    st.header("ç®¡ç†æª”æ¡ˆæœå°‹å•†åº—")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("å»ºç«‹æ–°å•†åº—")
        with st.form("create_store_form"):
            new_store_name = st.text_input(
                "å•†åº—åç¨±",
                placeholder="ä¾‹å¦‚: å‹å‹•æ³•è¦çŸ¥è­˜åº«"
            )
            create_btn = st.form_submit_button("â• å»ºç«‹å•†åº—", use_container_width=True)
            
            if create_btn and new_store_name:
                with st.spinner("æ­£åœ¨å»ºç«‹å•†åº—..."):
                    try:
                        store = client.file_search_stores.create(
                            config={'display_name': new_store_name}
                        )
                        st.success(f"âœ… æˆåŠŸå»ºç«‹å•†åº—: {new_store_name}")
                        st.info(f"å•†åº— ID: `{store.name}`")
                        time.sleep(1)
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ å»ºç«‹å¤±æ•—: {str(e)}")
    
    with col2:
        st.subheader("å¿«é€Ÿæ“ä½œ")
        if st.button("ğŸ”„ é‡æ–°æ•´ç†åˆ—è¡¨", use_container_width=True):
            st.cache_data.clear()
            st.rerun()
    
    st.divider()
    
    # é¡¯ç¤ºç¾æœ‰å•†åº—
    st.subheader("ç¾æœ‰å•†åº—åˆ—è¡¨")
    
    @st.cache_data(ttl=30)
    def get_stores():
        stores = []
        for store in client.file_search_stores.list():
            create_time = getattr(store, 'create_time', None)
            # è™•ç† datetime ç‰©ä»¶
            if create_time:
                if hasattr(create_time, 'strftime'):
                    create_time_str = create_time.strftime('%Y-%m-%d')
                else:
                    create_time_str = str(create_time)[:10]
            else:
                create_time_str = "æœªçŸ¥"
            
            stores.append({
                "name": store.name,
                "display_name": store.display_name or "æœªå‘½å",
                "create_time": create_time_str
            })
        return stores
    
    stores = get_stores()
    
    if not stores:
        st.info("ç›®å‰æ²’æœ‰ä»»ä½•å•†åº—,è«‹å»ºç«‹ä¸€å€‹æ–°å•†åº—")
    else:
        for i, store in enumerate(stores):
            with st.container():
                col1, col2, col3 = st.columns([3, 2, 1])
                
                with col1:
                    st.markdown(f"### ğŸ“¦ {store['display_name']}")
                    st.caption(f"ID: `{store['name']}`")
                
                with col2:
                    if store['create_time'] and store['create_time'] != "æœªçŸ¥":
                        st.metric("å»ºç«‹æ™‚é–“", store['create_time'])
                    else:
                        st.caption("å»ºç«‹æ™‚é–“: æœªçŸ¥")
                
                with col3:
                    delete_key = f"delete_{store['name']}"
                    if st.button("ğŸ—‘ï¸ åˆªé™¤", key=delete_key, type="secondary"):
                        try:
                            client.file_search_stores.delete(
                                name=store['name'],
                                config={'force': True}
                            )
                            st.success(f"å·²åˆªé™¤å•†åº—: {store['display_name']}")
                            st.cache_data.clear()
                            time.sleep(1)
                            st.rerun()
                        except Exception as e:
                            st.error(f"åˆªé™¤å¤±æ•—: {str(e)}")
                
                st.divider()

# ===== æ¨™ç±¤é  2: ä¸Šå‚³æª”æ¡ˆ =====
with tab2:
    st.header("ä¸Šå‚³æª”æ¡ˆåˆ°å•†åº—")
    
    # é¸æ“‡ç›®æ¨™å•†åº—
    stores = get_stores()
    
    if not stores:
        st.warning("âš ï¸ è«‹å…ˆå»ºç«‹ä¸€å€‹å•†åº—")
    else:
        store_options = {s["display_name"]: s["name"] for s in stores}
        selected_display = st.selectbox(
            "é¸æ“‡ç›®æ¨™å•†åº—",
            options=list(store_options.keys())
        )
        selected_store = store_options[selected_display]
        
        st.info(f"å°‡ä¸Šå‚³è‡³: **{selected_display}**")
        
        # ä¸Šå‚³æ–¹å¼é¸æ“‡
        upload_method = st.radio(
            "é¸æ“‡ä¸Šå‚³æ–¹å¼",
            options=["ç›´æ¥ä¸Šå‚³", "å…ˆä¸Šå‚³å¾ŒåŒ¯å…¥"],
            horizontal=True
        )
        
        # æª”æ¡ˆä¸Šå‚³
        uploaded_files = st.file_uploader(
            "é¸æ“‡æª”æ¡ˆ",
            accept_multiple_files=True,
            type=['txt', 'pdf', 'docx', 'xlsx', 'pptx', 'md', 'html', 'json', 'csv']
        )
        
        # é€²éšè¨­å®š
        with st.expander("âš™ï¸ é€²éšè¨­å®š"):
            col1, col2 = st.columns(2)
            
            with col1:
                use_custom_chunking = st.checkbox("è‡ªè¨‚åˆ†å¡Šè¨­å®š")
                if use_custom_chunking:
                    max_tokens = st.slider("æ¯å¡Šæœ€å¤§ Token æ•¸", 100, 1000, 200)
                    overlap_tokens = st.slider("é‡ç–Š Token æ•¸", 0, 100, 20)
            
            with col2:
                use_metadata = st.checkbox("æ–°å¢ä¸­ç¹¼è³‡æ–™")
                metadata_items = []
                if use_metadata:
                    st.markdown("**ä¸­ç¹¼è³‡æ–™è¨­å®š**")
                    author = st.text_input("ä½œè€…", key="meta_author")
                    year = st.number_input("å¹´ä»½", min_value=1900, max_value=2100, value=2024, key="meta_year")
                    category = st.text_input("åˆ†é¡", key="meta_category")
                    
                    if author:
                        metadata_items.append({"key": "author", "string_value": author})
                    if year:
                        metadata_items.append({"key": "year", "numeric_value": year})
                    if category:
                        metadata_items.append({"key": "category", "string_value": category})
        
        # ä¸Šå‚³æŒ‰éˆ•
        if st.button("ğŸš€ é–‹å§‹ä¸Šå‚³", type="primary", use_container_width=True):
            if not uploaded_files:
                st.warning("è«‹å…ˆé¸æ“‡æª”æ¡ˆ")
            else:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                total_files = len(uploaded_files)
                success_count = 0
                
                for idx, uploaded_file in enumerate(uploaded_files):
                    status_text.text(f"æ­£åœ¨è™•ç†: {uploaded_file.name} ({idx+1}/{total_files})")
                    
                    try:
                        # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ (è·¨å¹³å°ç›¸å®¹)
                        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
                            tmp_file.write(uploaded_file.getbuffer())
                            temp_path = tmp_file.name
                        
                        if upload_method == "ç›´æ¥ä¸Šå‚³":
                            # æº–å‚™è¨­å®š
                            config = {'display_name': uploaded_file.name}
                            
                            if use_custom_chunking:
                                config['chunking_config'] = {
                                    'white_space_config': {
                                        'max_tokens_per_chunk': max_tokens,
                                        'max_overlap_tokens': overlap_tokens
                                    }
                                }
                            
                            if metadata_items:
                                config['custom_metadata'] = metadata_items
                            
                            # ä¸Šå‚³
                            operation = client.file_search_stores.upload_to_file_search_store(
                                file=temp_path,
                                file_search_store_name=selected_store,
                                config=config
                            )
                        else:
                            # å…ˆä¸Šå‚³åˆ° Files API
                            sample_file = client.files.upload(
                                file=temp_path,
                                config={'name': uploaded_file.name}
                            )
                            
                            # æº–å‚™åŒ¯å…¥è¨­å®š
                            import_config = {}
                            if metadata_items:
                                import_config['custom_metadata'] = metadata_items
                            
                            # åŒ¯å…¥åˆ°å•†åº—
                            operation = client.file_search_stores.import_file(
                                file_search_store_name=selected_store,
                                file_name=sample_file.name,
                                **import_config
                            )
                        
                        # ç­‰å¾…æ“ä½œå®Œæˆ
                        while not operation.done:
                            time.sleep(2)
                            operation = client.operations.get(operation)
                        
                        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        try:
                            os.unlink(temp_path)
                        except:
                            pass
                        
                        success_count += 1
                        st.success(f"âœ… {uploaded_file.name} ä¸Šå‚³æˆåŠŸ")
                        
                    except Exception as e:
                        st.error(f"âŒ {uploaded_file.name} ä¸Šå‚³å¤±æ•—: {str(e)}")
                        # ç¢ºä¿æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                        try:
                            if 'temp_path' in locals():
                                os.unlink(temp_path)
                        except:
                            pass
                    
                    progress_bar.progress((idx + 1) / total_files)
                
                status_text.text(f"å®Œæˆ! æˆåŠŸä¸Šå‚³ {success_count}/{total_files} å€‹æª”æ¡ˆ")
                st.balloons()

# ===== æ¨™ç±¤é  3: çµ±è¨ˆè³‡è¨Š =====
with tab3:
    st.header("ç³»çµ±çµ±è¨ˆè³‡è¨Š")
    
    stores = get_stores()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("å•†åº—ç¸½æ•¸", len(stores))
    
    with col2:
        st.metric("æ”¯æ´æ ¼å¼", "20+ ç¨®")
    
    with col3:
        st.metric("æœ€å¤§æª”æ¡ˆ", "100 MB")
    
    st.divider()
    
    # å„å•†åº—è©³ç´°è³‡è¨Š
    if stores:
        st.subheader("å•†åº—åˆ—è¡¨")
        
        for store in stores:
            with st.expander(f"ğŸ“¦ {store['display_name']}"):
                st.markdown(f"**å•†åº— ID:** `{store['name']}`")
                st.markdown(f"**å»ºç«‹æ™‚é–“:** {store['create_time']}")
                
                # é¡¯ç¤ºå•†åº—è³‡è¨Š
                try:
                    store_info = client.file_search_stores.get(name=store['name'])
                    if hasattr(store_info, 'active_documents_count'):
                        st.metric("æ´»èºæ–‡ä»¶æ•¸", store_info.active_documents_count)
                except Exception as e:
                    st.info("ç„¡æ³•å–å¾—è©³ç´°è³‡è¨Š")
                
                st.markdown("---")
                st.caption("ğŸ’¡ æ³¨æ„: æª”æ¡ˆåŒ¯å…¥ FileSearchStore å¾Œæœƒè½‰ç‚ºåµŒå…¥å‘é‡,ç„¡æ³•ç›´æ¥åˆ—å‡ºæª”æ¡ˆæ¸…å–®")
    
    st.divider()
    
    # ç³»çµ±èªªæ˜
    with st.expander("ğŸ“– é—œæ–¼ FileSearchStore"):
        st.markdown("""
        ### FileSearchStore ç‰¹æ€§
        
        - âœ… **æ°¸ä¹…å„²å­˜**: è³‡æ–™æœƒç„¡é™æœŸä¿å­˜,é™¤éæ‰‹å‹•åˆªé™¤
        - âœ… **åµŒå…¥ç´¢å¼•**: æª”æ¡ˆè‡ªå‹•è½‰ç‚ºå‘é‡åµŒå…¥ä¸¦å»ºç«‹ç´¢å¼•
        - âœ… **èªæ„æœå°‹**: æ”¯æ´è‡ªç„¶èªè¨€æŸ¥è©¢
        - âš ï¸ **ä¸å¯åˆ—å‡º**: å·²åŒ¯å…¥çš„æª”æ¡ˆç„¡æ³•ç›´æ¥åˆ—å‡º,åªèƒ½é€éæŸ¥è©¢ä½¿ç”¨
        
        ### å„²å­˜å®¹é‡é™åˆ¶
        
        | å±¤ç´š | å®¹é‡ |
        |------|------|
        | å…è²»ç‰ˆ | 1 GB |
        | ç¬¬ 1 ç´š | 10 GB |
        | ç¬¬ 2 ç´š | 100 GB |
        | ç¬¬ 3 ç´š | 1 TB |
        
        ### æˆæœ¬èªªæ˜
        
        - **é¦–æ¬¡ç´¢å¼•**: $0.15 / ç™¾è¬ tokens
        - **å„²å­˜ç©ºé–“**: å…è²»
        - **æŸ¥è©¢åµŒå…¥**: å…è²»
        """)

# é å°¾
st.markdown("---")
st.caption("ğŸ’¡ æç¤º: ä¸Šå‚³çš„æª”æ¡ˆæœƒæ°¸ä¹…ä¿å­˜åœ¨ FileSearchStore ä¸­,é™¤éæ‰‹å‹•åˆªé™¤å•†åº—")