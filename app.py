import streamlit as st
from google import genai
from google.genai import types
import json
import os
from datetime import datetime

# é é¢é…ç½®
st.set_page_config(
    page_title="ä¼æ¥­æ³•è¦æŸ¥è©¢ç³»çµ±",
    page_icon="ğŸ“š",
    layout="wide"
)

# åˆå§‹åŒ– Gemini å®¢æˆ¶ç«¯
@st.cache_resource
def init_client():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
        st.info("è«‹åœ¨çµ‚ç«¯åŸ·è¡Œ: export GEMINI_API_KEY='your-api-key'")
        st.stop()
    return genai.Client(api_key=api_key)

try:
    client = init_client()
except Exception as e:
    st.error(f"åˆå§‹åŒ–å®¢æˆ¶ç«¯å¤±æ•—: {str(e)}")
    st.info("è«‹ç¢ºèªå·²æ­£ç¢ºè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
    st.stop()

# å´é‚Šæ¬„é…ç½®
with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±è¨­å®š")
    
    # å–å¾—æ‰€æœ‰å¯ç”¨çš„ FileSearchStore
    @st.cache_data(ttl=60)
    def get_file_search_stores():
        try:
            stores = []
            for store in client.file_search_stores.list():
                stores.append({
                    "name": store.name,
                    "display_name": store.display_name or store.name
                })
            return stores
        except Exception as e:
            st.error(f"ç„¡æ³•è¼‰å…¥æª”æ¡ˆæœå°‹å•†åº—: {str(e)}")
            return []
    
    stores = get_file_search_stores()
    
    if not stores:
        st.warning("âš ï¸ å°šæœªå»ºç«‹ä»»ä½•æª”æ¡ˆæœå°‹å•†åº—")
        st.info("è«‹å…ˆä½¿ç”¨å¾Œç«¯ç®¡ç†ç¨‹å¼ä¸Šå‚³æª”æ¡ˆ")
        selected_store = None
    else:
        store_options = {s["display_name"]: s["name"] for s in stores}
        selected_display = st.selectbox(
            "é¸æ“‡çŸ¥è­˜åº«",
            options=list(store_options.keys())
        )
        selected_store = store_options[selected_display]
        
        # é¡¯ç¤ºå•†åº—è³‡è¨Š
        st.success(f"âœ… å·²é¸æ“‡: {selected_display}")
    
    st.divider()
    
    # ç³»çµ±æç¤ºè©è¨­å®š
    st.subheader("ğŸ“ ç³»çµ±æç¤ºè©")
    
    # é è¨­çš„æ³•è¦æŸ¥è©¢ç³»çµ±æç¤ºè©
    default_system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ³•è¦æŸ¥è©¢åŠ©æ‰‹ã€‚è«‹éµå¾ªä»¥ä¸‹è¦å‰‡å›ç­”å•é¡Œ:

1. **ç›´æ¥åˆ—å‡ºç›¸é—œæ³•è¦æ¢æ–‡**: å®Œæ•´å¼•ç”¨æ¢æ–‡å…§å®¹,ä¸è¦çœç•¥
2. **ä¸è¦è§£é‡‹èªªæ˜**: åªæä¾›æ³•æ¢åŸæ–‡,ä¸éœ€è¦é¡å¤–è§£é‡‹æˆ–è©•è«–
3. **æ˜ç¢ºæ¨™è¨»å‡ºè™•**: æ¯æ¢æ³•è¦å¿…é ˆæ¨™è¨»æ³•è¦åç¨±ã€æ¢è™Ÿå’Œé …æ¬¡

å›ç­”æ ¼å¼ç¯„ä¾‹:
ã€å‹å‹•åŸºæº–æ³•ç¬¬30æ¢ã€‘
å‹å·¥æ­£å¸¸å·¥ä½œæ™‚é–“,æ¯æ—¥ä¸å¾—è¶…éå…«å°æ™‚,æ¯é€±ä¸å¾—è¶…éå››åå°æ™‚ã€‚

ã€å‹å‹•åŸºæº–æ³•ç¬¬32æ¢ç¬¬1é …ã€‘
é›‡ä¸»æœ‰ä½¿å‹å·¥åœ¨æ­£å¸¸å·¥ä½œæ™‚é–“ä»¥å¤–å·¥ä½œä¹‹å¿…è¦è€…,é›‡ä¸»ç¶“å·¥æœƒåŒæ„,å¦‚äº‹æ¥­å–®ä½ç„¡å·¥æœƒè€…,ç¶“å‹è³‡æœƒè­°åŒæ„å¾Œ,å¾—å°‡å·¥ä½œæ™‚é–“å»¶é•·ä¹‹ã€‚

è«‹åš´æ ¼éµå¾ªä»¥ä¸Šæ ¼å¼,ç¢ºä¿å¼•ç”¨æº–ç¢ºã€‚"""
    
    use_custom_prompt = st.checkbox("è‡ªè¨‚ç³»çµ±æç¤ºè©", value=False)
    
    if use_custom_prompt:
        system_prompt = st.text_area(
            "ç³»çµ±æç¤ºè©",
            value=default_system_prompt,
            height=300,
            help="å®šç¾© AI åŠ©æ‰‹çš„è¡Œç‚ºå’Œå›ç­”é¢¨æ ¼"
        )
    else:
        system_prompt = default_system_prompt
        with st.expander("æŸ¥çœ‹é è¨­æç¤ºè©"):
            st.code(default_system_prompt, language="text")
    
    st.divider()
    
    # æœå°‹è¨­å®š
    st.subheader("ğŸ” æœå°‹è¨­å®š")
    
    use_metadata_filter = st.checkbox("ä½¿ç”¨ä¸­ç¹¼è³‡æ–™ç¯©é¸", value=False)
    metadata_filter = ""
    
    if use_metadata_filter:
        metadata_filter = st.text_input(
            "ç¯©é¸æ¢ä»¶",
            placeholder='ä¾‹å¦‚: author="æ³•å‹™éƒ¨"',
            help="ä½¿ç”¨ AIP-160 èªæ³•,ä¾‹å¦‚: author=\"æ³•å‹™éƒ¨\" AND year>=2023"
        )
    
    # æ¨¡å‹é¸æ“‡
    model_choice = st.selectbox(
        "é¸æ“‡æ¨¡å‹",
        options=[
            "gemini-2.5-flash",
            "gemini-2.5-pro",
            "gemini-3-pro-preview"
        ],
        index=0
    )
    
    if st.button("ğŸ”„ é‡æ–°æ•´ç†å•†åº—åˆ—è¡¨"):
        st.cache_data.clear()
        st.rerun()

# ä¸»è¦å…§å®¹å€
st.title("ğŸ“š ä¼æ¥­æ³•è¦æŸ¥è©¢ç³»çµ±")
st.markdown("---")

# åˆå§‹åŒ–å°è©±æ­·å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# åˆå§‹åŒ– chunks è¨˜éŒ„
if "chunks_history" not in st.session_state:
    st.session_state.chunks_history = []

# é¡¯ç¤ºå°è©±æ­·å²
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # é¡¯ç¤ºå¼•ç”¨ä¾†æº
        if "citations" in message and message["citations"]:
            with st.expander("ğŸ“– å¼•ç”¨ä¾†æº", expanded=False):
                for i, citation in enumerate(message["citations"], 1):
                    st.markdown(f"**ä¾†æº {i}:**")
                    st.markdown(f"- æ–‡ä»¶: `{citation['document']}`")
                    if citation.get('chunk_id'):
                        st.markdown(f"- å€å¡Š: `{citation['chunk_id']}`")
                    st.markdown("---")
        
        # é¡¯ç¤ºæª¢ç´¢åˆ°çš„ chunks
        if message["role"] == "assistant" and idx < len(st.session_state.chunks_history):
            chunks_data = st.session_state.chunks_history[idx]
            if chunks_data:
                with st.expander(f"ğŸ” æŸ¥çœ‹æª¢ç´¢å…§å®¹ ({len(chunks_data)} å€‹å€å¡Š)", expanded=False):
                    for i, chunk in enumerate(chunks_data, 1):
                        st.markdown(f"### ğŸ“„ å€å¡Š {i}")
                        st.markdown(f"**ä¾†æº:** {chunk.get('source', 'Unknown')}")
                        st.markdown("**å…§å®¹:**")
                        st.text_area(
                            f"chunk_{idx}_{i}",
                            value=chunk.get('text', ''),
                            height=150,
                            disabled=True,
                            label_visibility="collapsed"
                        )
                        if i < len(chunks_data):
                            st.markdown("---")

# æŸ¥è©¢è¼¸å…¥
if selected_store:
    query = st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...")
    
    if query:
        # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(query)
        
        # ç”Ÿæˆå›æ‡‰
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒ..."):
                try:
                    # æº–å‚™å·¥å…·é…ç½®
                    file_search_config = types.FileSearch(
                        file_search_store_names=[selected_store]
                    )
                    
                    if use_metadata_filter and metadata_filter:
                        file_search_config.metadata_filter = metadata_filter
                    
                    # æº–å‚™è¨Šæ¯å…§å®¹ (åŠ å…¥ç³»çµ±æç¤ºè©)
                    contents = [
                        types.Content(
                            role="user",
                            parts=[types.Part(text=system_prompt)]
                        ),
                        types.Content(
                            role="model",
                            parts=[types.Part(text="æˆ‘äº†è§£ã€‚æˆ‘æœƒåš´æ ¼éµå¾ªæ‚¨çš„æŒ‡ç¤º:åªåˆ—å‡ºæ³•è¦æ¢æ–‡åŸæ–‡,ä¸åšè§£é‡‹,ä¸¦æ˜ç¢ºæ¨™è¨»å‡ºè™•ã€‚")]
                        ),
                        types.Content(
                            role="user",
                            parts=[types.Part(text=query)]
                        )
                    ]
                    
                    # å‘¼å« Gemini API
                    response = client.models.generate_content(
                        model=model_choice,
                        contents=contents,
                        config=types.GenerateContentConfig(
                            tools=[
                                types.Tool(file_search=file_search_config)
                            ]
                        )
                    )
                    
                    # é¡¯ç¤ºå›æ‡‰
                    answer = response.text
                    st.markdown(answer)
                    
                    # è™•ç†å¼•ç”¨è³‡è¨Š
                    citations = []
                    chunks_data = []
                    
                    if hasattr(response.candidates[0], 'grounding_metadata'):
                        grounding = response.candidates[0].grounding_metadata
                        
                        # æå–å¼•ç”¨
                        if grounding and hasattr(grounding, 'grounding_chunks'):
                            for chunk in grounding.grounding_chunks:
                                # æå–å¼•ç”¨è³‡è¨Š
                                if hasattr(chunk, 'web') and chunk.web:
                                    citations.append({
                                        'document': chunk.web.uri if hasattr(chunk.web, 'uri') else 'Unknown',
                                        'chunk_id': chunk.web.title if hasattr(chunk.web, 'title') else ''
                                    })
                                
                                # æå– chunk å…§å®¹
                                chunk_info = {}
                                if hasattr(chunk, 'web') and chunk.web:
                                    chunk_info['source'] = chunk.web.uri if hasattr(chunk.web, 'uri') else 'Unknown'
                                    chunk_info['text'] = chunk.web.title if hasattr(chunk.web, 'title') else ''
                                
                                # å˜—è©¦ç²å–å¯¦éš›æ–‡æœ¬å…§å®¹
                                if hasattr(chunk, 'retrieved_context'):
                                    chunk_info['text'] = chunk.retrieved_context.text if hasattr(chunk.retrieved_context, 'text') else str(chunk.retrieved_context)
                                elif hasattr(chunk, 'text'):
                                    chunk_info['text'] = chunk.text
                                
                                if chunk_info:
                                    chunks_data.append(chunk_info)
                        
                        # å¦‚æœæœ‰ grounding_supports,ä¹Ÿå˜—è©¦æå–
                        if grounding and hasattr(grounding, 'grounding_supports'):
                            for support in grounding.grounding_supports:
                                if hasattr(support, 'segment'):
                                    chunk_info = {
                                        'source': 'Grounding Support',
                                        'text': support.segment.text if hasattr(support.segment, 'text') else str(support.segment)
                                    }
                                    chunks_data.append(chunk_info)
                    
                    # é¡¯ç¤ºå¼•ç”¨
                    if citations:
                        with st.expander("ğŸ“– å¼•ç”¨ä¾†æº", expanded=False):
                            for i, citation in enumerate(citations, 1):
                                st.markdown(f"**ä¾†æº {i}:**")
                                st.markdown(f"- æ–‡ä»¶: `{citation['document']}`")
                                if citation.get('chunk_id'):
                                    st.markdown(f"- å€å¡Š: `{citation['chunk_id']}`")
                                st.markdown("---")
                    
                    # é¡¯ç¤ºæª¢ç´¢åˆ°çš„ chunks
                    if chunks_data:
                        with st.expander(f"ğŸ” æŸ¥çœ‹æª¢ç´¢å…§å®¹ ({len(chunks_data)} å€‹å€å¡Š)", expanded=False):
                            for i, chunk in enumerate(chunks_data, 1):
                                st.markdown(f"### ğŸ“„ å€å¡Š {i}")
                                st.markdown(f"**ä¾†æº:** {chunk.get('source', 'Unknown')}")
                                st.markdown("**å…§å®¹:**")
                                st.text_area(
                                    f"chunk_new_{i}",
                                    value=chunk.get('text', ''),
                                    height=150,
                                    disabled=True,
                                    label_visibility="collapsed"
                                )
                                if i < len(chunks_data):
                                    st.markdown("---")
                    
                    # å„²å­˜åˆ°å°è©±æ­·å²
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": answer,
                        "citations": citations
                    })
                    
                    # å„²å­˜ chunks åˆ°æ­·å²
                    # éœ€è¦ç‚ºæ¯å€‹ assistant è¨Šæ¯å„²å­˜å°æ‡‰çš„ chunks
                    # è¨ˆç®—ç•¶å‰æ˜¯ç¬¬å¹¾å€‹ assistant è¨Šæ¯
                    assistant_msg_count = sum(1 for m in st.session_state.messages if m["role"] == "assistant")
                    while len(st.session_state.chunks_history) < assistant_msg_count:
                        st.session_state.chunks_history.append(None)
                    st.session_state.chunks_history[-1] = chunks_data
                    
                except Exception as e:
                    error_msg = f"âŒ æŸ¥è©¢å¤±æ•—: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": error_msg
                    })
                    st.session_state.chunks_history.append(None)

else:
    st.info("ğŸ‘ˆ è«‹å…ˆåœ¨å´é‚Šæ¬„é¸æ“‡çŸ¥è­˜åº«")

# æ¸…é™¤å°è©±æŒ‰éˆ•
if st.session_state.messages:
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±æ­·å²", use_container_width=True):
            st.session_state.messages = []
            st.session_state.chunks_history = []
            st.rerun()
    with col2:
        if st.button("ğŸ’¾ åŒ¯å‡ºå°è©±è¨˜éŒ„", use_container_width=True):
            import json
            from datetime import datetime
            
            export_data = {
                "exported_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "knowledge_base": selected_display if selected_store else "None",
                "conversation": st.session_state.messages
            }
            
            json_str = json.dumps(export_data, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ JSON",
                data=json_str,
                file_name=f"conversation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )

# é å°¾
st.markdown("---")
st.caption(f"ğŸ’¡ æç¤º: æ‚¨å¯ä»¥è©¢å•æ³•è¦ç›¸é—œå•é¡Œ,ç³»çµ±æœƒå¾çŸ¥è­˜åº«ä¸­æœå°‹ç›¸é—œå…§å®¹ä¸¦æä¾›ç­”æ¡ˆ | ç•¶å‰æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")